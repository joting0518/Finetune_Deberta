# AES: Automatic Essay Scoring using DeBERTa

This project focuses on **Automatic Essay Scoring (AES)**, particularly tailored for **IELTS writing tasks**. We fine-tune a DeBERTa model to assess writing quality either as a **classification** or **regression** task.

## ğŸ§  Core Idea

Using pretrained language models like `microsoft/deberta-v3-base`, we fine-tune on IELTS writing data to predict human-like writing scores.

## ğŸ“Š Experiment: Regression vs Classification in AES

During the fine-tuning of the DeBERTa language model for AES (Automatic Essay Scoring), we experimented with two different objective functions: **regression** and **classification**.

### ğŸ“‰ Regression Training Results

As shown in the figure below, when training the model with a **regression objective**, the loss failed to converge properly and continued to fluctuate over time.

![Regression Loss Trends](./images/regression_loss.png)

*Figure 3. Regression task training loss trends.*

Further evaluation showed that the model's predicted average score was 6.0. Upon analysis, we found this was due to **imbalanced data distribution**, which made it difficult for the model to learn meaningful score representations through regression. The essay score distribution is shown below:

![Score Distribution](./images/score_distribution.png)

*Figure 4. Histogram of score distribution (Total essays: 3,676).*

### âœ… Classification Training Results

To address the convergence issue, we re-formulated the problem as a **classification task**. Scores were mapped into 19 discrete classes, and the model was trained using **Cross-Entropy loss**.

This approach allowed the model to learn more robustly from the data and converge successfully, as illustrated in the following loss curves:

![Classification Loss Trends](./images/classification_loss.png)

*Figure 5. Classification task training loss trends.*

Final evaluation results show that the model's predicted scores closely match human-labeled scores, with a **Mean Absolute Error (MAE) of 0.7064**, which is approximately within Â±0.5 band of the true IELTS scoring range.

---

**Conclusion:**  
Formulating AES as a **classification** task provides significantly better training stability and scoring accuracy compared to regression, especially when working with imbalanced writing score distributions.

### file structure
writing_score_model/
â”‚
â”œâ”€â”€ dataset/                        #è³‡æ–™è™•ç†ç›¸é—œ
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ dataset.py                  #Datasetè™•ç†ç¨‹å¼ç¢¼
â”‚   â””â”€â”€ preprocessing.py            #è³‡æ–™æ¸…ç†å’Œé è™•ç†ç¨‹å¼
â”‚
â”œâ”€â”€ model/                          #æ¨¡å‹å®šç¾©
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ deberta_model.py            #å¾®èª¿çš„ DeBERTa æ¨¡å‹å®šç¾©
â”‚
â”œâ”€â”€ script/                         #è¨“ç·´å’Œæ¸¬è©¦è…³æœ¬
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ train.py                    #æ¨¡å‹è¨“ç·´ç¨‹å¼
â”‚   â”œâ”€â”€ evaluate.py                 #æ¨¡å‹è©•ä¼°ç¨‹å¼
â”‚   â”œâ”€â”€ config.json                 #è¨“ç·´åƒæ•¸çš„é…ç½®æª”æ¡ˆ
â”‚   â””â”€â”€ main.py                     #ä¸»ç¨‹å¼å…¥å£ï¼Œè² è²¬èª¿åº¦æ•´å€‹æµç¨‹
â”‚
â”œâ”€â”€ util/                           #å·¥å…·å‡½æ•¸ (loss, optimizer, scheduler)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ load_model.py               #æ¨¡å‹è¼‰å…¥å‡½æ•¸
â”‚   â”œâ”€â”€ loss.py                     #å®šç¾©æå¤±å‡½æ•¸
â”‚   â”œâ”€â”€ optimizer.py                #å„ªåŒ–å™¨è¨­ç½®
â”‚   â”œâ”€â”€ scheduler.py                #Scheduler è¨­ç½®
â”‚   â””â”€â”€ tokenizer.py                #Tokenizer åˆå§‹åŒ–
â”‚
â”œâ”€â”€ logs/                           #è¨“ç·´æ—¥èªŒ
â”‚
â”œâ”€â”€ saved_model/                    #å·²è¨“ç·´å¥½çš„æ¨¡å‹
â”‚
â”œâ”€â”€ preprocess_dataset_test.csv     #å¯«ä½œè©•åˆ†æ¸¬è©¦é›†
â””â”€â”€ preprocess_dataset_train.csv    #å¯«ä½œè©•åˆ†è¨“ç·´é›†
